# A Real-World Test of Artificial Intelligence Infiltration of a University Examination System: A “Turing Test” Case Study

## Citation Information

- Author(s): Peter Scarfe, Kelly Watcham, Alasdair Clarke, Etienne Roesch
- Title: A Real-World Test of Artificial Intelligence Infiltration of a University Examination System: A “Turing Test” Case Study
- Journal/Source: PLOS ONE
- Publication Year: 2024
- DOI/URL: 10.1371/journal.pone.0305354
- Affiliation: University of Reading, University of Essex

## Audience

- Target Audience: Educators, policymakers in academic integrity, AI ethics researchers, and developers of educational tools.
- Application: Use findings to develop robust frameworks for integrating or countering AI use in academic assessments.
- Outcome: Improved understanding of the vulnerabilities of current examination systems and better preparation for AI’s educational implications.

## Relevance

- Significance: Highlights the challenges posed by AI systems like ChatGPT in maintaining academic integrity.
- Real-world Implications: This study emphasizes the need for universities to adapt examination systems in response to the growing accessibility and capabilities of AI tools.

## Conclusions

- Takeaways:

  1. AI submissions were largely undetectable (94% undetected), posing risks to academic integrity.
  2. AI submissions generally outperformed student work, with grades averaging half a classification boundary higher.
  3. AI tools threaten traditional unsupervised exam formats, necessitating educational reform.
  4. Practical Implications: Universities must either reintegrate supervised assessments or redesign exams to reflect the reality of AI usage.
  5. Potential Impact: Could redefine how educational institutions approach both teaching and evaluating student learning.

## Contextual Insight

## Abstract in a Nutshell

This study evaluates the infiltration of AI (GPT-4) into university examination systems through a blind test. It demonstrates how AI submissions, using unsupervised take-home exams, went largely undetected and outperformed real students.

## Abstract Keywords

- Artificial Intelligence (AI)
- Academic Integrity
- Large Language Models (LLMs)
- Examination Systems
- Cheating Detection

## Gap/Need

The study addresses the lack of empirical data on AI’s detectability in real-world examination settings.

## Innovation

This research provides a rigorous, real-world analysis of AI’s performance and detectability, moving beyond theoretical discussions.

## Key Quotes

 1. “AI submissions consistently outperformed real students, attaining grades on average around half a classification boundary higher.”
 2. “94% of our AI submissions were undetected, even though we used AI in the most detectable way possible.”
 3. “The rapid integration of AI into assessments poses an unprecedented challenge to the academic integrity of higher education.”

Questions and Answers

 1. How detectable are AI-generated exam submissions?
 • 94% were undetected.
 2. Do AI submissions outperform student work?
 • Yes, they consistently achieved higher grades.
 3. What are the implications for education?
 • Current unsupervised exam systems are vulnerable, requiring systemic reform.

## Paper Details

### Purpose/Objective

- Goal: To evaluate the ability of GPT-4 to infiltrate and perform in university examinations undetected.
 • Research Questions: Can AI submissions remain undetected in real-world university assessments? How do they perform relative to human students?

### Methodology

- Research Design: Blind real-world test injecting AI submissions into undergraduate psychology exams.
- Participants: Five modules with a mix of short-answer and essay-based exams.
- Data Collection: AI submissions generated using GPT-4 with minimal editing; markers were unaware.
- Data Analysis: Grades and detection rates analyzed across modules.

### Main Results/Findings

- Metrics:
  - Detection Rate: 6% (94% undetected).
  - Grade Comparison: AI submissions achieved higher median grades in 4 of 5 modules.
  - Data Availability: Accessible via OSF.

### Limitations

- Results may not generalize across disciplines or with future AI advancements.

### Proposed Future Work

- Explore detection methods for AI usage.
- Investigate AI’s performance in more abstract and advanced reasoning tasks.

## AutoExpert Insights and Commentary

- Critiques: The study could further explore how iterative use by students might impact detectability and performance.
- Praise: Rigorous design and practical relevance make it a pivotal contribution to understanding AI’s impact on education.
- Questions: How can educators balance the use of AI as a tool while preserving academic integrity?
